# we expect the number of daily cases to stabilised at the mean of the observed incidence in the
# time window of interest
# this is use for the prior of initial number of cases, i.e. as the mean of an exponential distribution
# in practice, the mu0 cases will happen 100 days before the start of the time windows
theta0 <- c(rep(1,N_geo), mu0)          # initial parameter R=1 (time # of locations, and initial number of cases in the past)
# number of locations
N_geo <- ncol(incidence)-1
# Serial interval
mean_SI <- 14.2
CV_SI <- 9.6/14.2 # from http://www.nejm.org/doi/suppl/10.1056/NEJMc1414992/suppl_file/nejmc1414992_
SI <- SI_gamma_dist_EpiEstim(mu = mean_SI,
cv = CV_SI,
SItrunc = 40)
# final number of MCMC iterations (the whole thing,
# here with 10 locations runs in ~3.5mins) )
rep <- 2e3
sigma_prop <- rep(0.1,N_geo*2)         # initial proposal variances (they are now tuned!)
# initial incidence conditions
if ( N_geo>1 ){
mu0 <- colMeans(incidence[,-1])*mean_SI
}else{
mu0 <- mean(incidence[,-1])*mean_SI
}
# initially, we assume R=1 and choose initial condition accordingly, i.e. with mu0 case and R=1
# we expect the number of daily cases to stabilised at the mean of the observed incidence in the
# time window of interest
# this is use for the prior of initial number of cases, i.e. as the mean of an exponential distribution
# in practice, the mu0 cases will happen 100 days before the start of the time windows
theta0 <- c(rep(1,N_geo), mu0)          # initial parameter R=1 (time # of locations, and initial number of cases in the past)
res <- MCMC_full(I = incidence,
N_geo = N_geo,
iter = rep,
theta0 = theta0,
s = sigma_prop,
SI = SI,
mu0 = mu0,
repli_adapt = 10,
within_iter = rep/10, over_disp = over_d)
Acc <- colSums(diff(res$theta)!=0)/rep          # acceptance rate (should be close to .2)
Acc
# plot traces
plot(res$logL[,1])                                  # of likelihood
layout(matrix(1:N_geo,2,ceiling(N_geo/2),byrow = TRUE))
for (i in 1:N_geo) plot(res$theta[,i])              # of R's
for (i in 1:N_geo) plot(res$theta[,N_geo+i])        # of initial conditions
if (N_geo>1){
R_est <- apply(res$theta[,1:N_geo],2,
quantile,c(.5,.025,.975))   # median and 95%CrI of Rs by locations
I0_est <- apply(res$theta[,(N_geo+1):(2*N_geo)],2,
quantile,c(.5,.025,.975))   # median and 95%CrI of I0
}else{
R_est <- quantile(res$theta[,1],c(.5,.025,.975))
I0_est <- quantile(res$theta[,2],c(.5,.025,.975))
}
save.image('test_on_simulation1.RData')             # saving so far
layout(matrix(1:2,1,2,byrow = TRUE))
errbar(1:N_geo,R_est[1,],R_est[2,],R_est[3,],
xlab = 'location', ylab = 'R',ylim = c(0,3), bty = 'n')
lines(c(1,N_geo),rep(R,2), col = 'red')
I0 <- 5
dat=rep(5,I0)
i <- incidence::incidence(dat)  # 20 cases to start with
dat
SItrunc <- 2
SI_Distr <- c(0,1)
SI_Distr <- SI_Distr / sum(SI_Distr)
R <- 1.5
over_d <- .52
pred <- projections::project(x = i, R = rep(R,2), R_fix_within = TRUE,
si = SI_Distr, n_days = 100, n_sim = 2e2, model = "negbin" , size = over_d)
temp <- as.matrix(pred)
temp <- as.matrix(pred)
cum_inc <- colSums(temp)
cum_inc
incidence <- data.frame(date = as.Date('01/05/2018',format='%d/%m/%Y')+seq(0,4*7-1),
I = tail(temp,4*7))
f <- which(colSums(incidence[,-1])==0) # remove location with 0 cases in last 20 days
f
f <- which(colSums(incidence[,-1])==0) # remove location with 0 cases in last 20 days
if (length(f)>0) incidence <- incidence[,-(f+1)]
incidence <- incidence[,1:11]
colSums(incidence[,-1])
incidence <- data.frame(date = as.Date('01/05/2018',format='%d/%m/%Y')+seq(0,4*7-1),
I = tail(temp,4*7))
matplot(incidence)
matplot(incidence[2:30])
pred <- projections::project(x = i, R = rep(R,2), R_fix_within = TRUE,
si = SI_Distr, n_days = 5, n_sim = 2e2, model = "negbin" , size = over_d)
temp <- as.matrix(pred)
cum_inc <- colSums(temp)
incidence <- data.frame(date = as.Date('01/05/2018',format='%d/%m/%Y')+seq(0,5-1),
I = tail(temp,5))
matplot(incidence[2:30])
View(incidence)
incidence[2:(n_t),2:n]/incidence[1:(n_t-1),2:n]
n <- 2e2
n_t <- 5
pred <- projections::project(x = i, R = rep(R,2), R_fix_within = TRUE,
si = SI_Distr, n_days = n_t, n_sim = n, model = "negbin" , size = over_d)
temp <- as.matrix(pred)
cum_inc <- colSums(temp)
ratio <- incidence[2:(n_t),2:n]/incidence[1:(n_t-1),2:n]
View(ratio)
mean(ratio,na.rm=TRUE)
mean(ratio,na.rm = TRUE)
f<- which(is.na(ratio))
ratio[4]
mean(as.vector(ratio),na.rm = TRUE)
mean(c(1,2),na.rm=TRUE)
mean(c(1,2,NA),na.rm=TRUE)
mean(c(1,2,NaN),na.rm=TRUE)
x <- as.vector(ratio)
View(x)
x <- c(ratio)
x <- as.matrix(ratio)
View(x)
mean(x,na.rm = TRUE)
mean(ratio,na.rm = TRUE)
ratio <- as.matrix(incidence[2:(n_t),2:n]/incidence[1:(n_t-1),2:n]()
mean(ratio,na.rm = TRUE)
ratio <- as.matrix(incidence[2:(n_t),2:n]/incidence[1:(n_t-1),2:n]()
mean(ratio,na.rm = TRUE)
ratio <- as.matrix(incidence[2:(n_t),2:n]/incidence[1:(n_t-1),2:n])
mean(ratio,na.rm = TRUE)
library(devtools)
install_github('pnouvellet/ebolaproj/ebolaproj')
install_github('pnouvellet/ebolaproj/ebolaproj',force=TRUE)
library(ebolaproj)
install_github('pnouvellet/ebolaproj/ebolaproj',ref='negBin',force=TRUE)
library(ebolaproj)
LikeNb
incidence <- as.matrix(incidence[,2:n])
ratio <- incidence[2:(n_t),]/incidence[1:(n_t-1),]
mean(ratio,na.rm = TRUE)
rnbinom(n = 1e2, mu = R*10, size = 0.5)
Xt <- 10
x <- rnbinom(n = 1e2, mu = R*Xt, size = 0.5)
x <- rnbinom(n = 1e2, mu = R*Xt, size = 0.5)
mean(x)/Xt
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
mean(x)/Xt
mean(x)^2/(Xt*(var(x)-mean(x)))
mean(x)/Xt
mean(x)^2/(Xt*(var(x)-mean(x)))
x_obs <- rbinom(n = 1e3, size = x, prob = p)
p <- 0.5
x_obs <- rbinom(n = 1e3, size = x, prob = p)
mean(x_obs)/Xt_obs
Xt_obs <- Xt*p
mean(x_obs)/Xt_obs
mean(x_obs)^2/(Xt_obs*(var(x_obs)-mean(x_obs)))
sd(x)/mean(x)
sd(x_obs)/mean(x_obs)
sd(x)/mean(x)
sd(x_obs)/mean(x_obs)
1+R/.5
R
var(x)
Xt*R+Xt*R^2/.5
Xt*R+Xt^2*R^2/.5
var(x)
mean(x)+mean(x)^2/.5
var(x)
Xt*R+Xt^2*R^2/.5
function (x, y = NULL, na.rm = FALSE, use)
var(x)
var(x)
Xt*R+Xt^2*R^2/.5
mean(x)+mean(x)^2/.5
mean(x)^2/(Xt*(var(x)-mean(x)))
mean(x)^2/((var(x)-mean(x)))
mean(x)^2/(Xt*(var(x)-mean(x)))
mean(x)^2/((var(x)-mean(x)))
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
p <- 0.5
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
sd(x_obs)/mean(x_obs)
sd(x)/mean(x)
Xt <- 10
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
sd(x)/mean(x)
var(x)
Xt*R+Xt^2*R^2/.5
mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
Xt <- 10
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
Xt <- 100
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
Xt <- 1000
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
Xt <- 1000
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
Xt <- 1000
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
Xt <- 10
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
Xt <- 10
x <- rnbinom(n = 1e1, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
Xt <- 10
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.05
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
Xt <- 10
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.75
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
hist(x_obs)
hist(cbind(x_obs,rnbinom(n = 1e3, mu = R*Xt*p, size = 0.5)))
hist(x_obs)
hist(rnbinom(n = 1e3, mu = R*Xt*p, size = 0.5),add=TRUE)
hist(x_obs,col=rgb(1,0,0,0.5))
hist(rnbinom(n = 1e3, mu = R*Xt*p, size = 0.5),add=TRUE,col=rgb(0,0,1,0.5))
Xt <- 10
x <- rnbinom(n = 1e3, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.75
x_obs <- rbinom(n = 1e3, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
hist(x_obs,col=rgb(1,0,0,0.5))
hist(rnbinom(n = 1e3, mu = R*Xt*p, size = 0.5),add=TRUE,col=rgb(0,0,1,0.5))
Xt <- 10
x <- rnbinom(n = 1e4, mu = R*Xt, size = 0.5)
# mean(x)/Xt
mean(x)^2/((var(x)-mean(x)))
# sd(x)/mean(x)
# var(x)
# Xt*R+Xt^2*R^2/.5
# mean(x)+mean(x)^2/.5
### underrepot
p <- 0.75
x_obs <- rbinom(n = 1e4, size = x, prob = p)
Xt_obs <- Xt*p
# mean(x_obs)/Xt_obs
mean(x_obs)^2/((var(x_obs)-mean(x_obs)))
# sd(x_obs)/mean(x_obs)
# 1+R/.5
hist(x_obs,col=rgb(1,0,0,0.5))
hist(rnbinom(n = 1e4, mu = R*Xt*p, size = 0.5),add=TRUE,col=rgb(0,0,1,0.5))
library(incidence)
library(projections)
library(epitrix)
library(EpiEstim)
library(Hmisc)
library(ebolaproj)
I0 <- 5
dat=rep(5,I0)
## simulate basic epicurvedat <- c(0, 2, 2, 3, 3, 5, 5, 5, 6, 6, 6, 6)
i <- incidence::incidence(dat)  # 20 cases to start with
# plot(i)
# SI
mean_SI <- 14.2
CV_SI <- 9.6/14.2 # from http://www.nejm.org/doi/suppl/10.1056/NEJMc1414992/suppl_file/nejmc1414992_
# params <- gamma_mucv2shapescale(mean_SI, CV_SI)
# si <- distcrete("gamma", interval = 1L,
#                   shape = params$shape,
#                   scale = params$scale, w = 0.5)
# si$d(0:30) # problem of first one
SItrunc <- 40
# serial distribution
SI_Distr <- EpiEstim::discr_si(0:SItrunc,mean_SI,mean_SI*CV_SI)
SI_Distr <- SI_Distr / sum(SI_Distr)
#simulate 40 days
R <- 1.5
over_d <- .52
# pred <- projections::project(x = i, R = rep(R,2), R_fix_within = TRUE,
#                 si = SI_Distr, n_days = 100, n_sim = 2e2, model = "poisson" )
pred <- projections::project(x = i, R = rep(R,2), R_fix_within = TRUE,
si = SI_Distr, n_days = 100, n_sim = 2e2, model = "negbin" , size = over_d)
temp <- as.matrix(pred)
cum_inc <- colSums(temp)
cum_inc
mean(cum_inc)
# keep incidence of last 20 days
incidence <- data.frame(date = as.Date('01/05/2018',format='%d/%m/%Y')+seq(0,4*7-1),
I = tail(temp,4*7))
f <- which(colSums(incidence[,-1])==0) # remove location with 0 cases in last 20 days
if (length(f)>0) incidence <- incidence[,-(f+1)]
incidence <- incidence[,1:11]
colSums(incidence[,-1])
# I_cum_hist <- colSums(head(pred,150-20))
# save(incidence,R, file = 'simulated_nb.RData')
# rm(list = as.vector(ls()))
# devtools::load_all('.')
library(ebolaproj)
# load sample data to check
# load(file = 'simulated_nb.RData')
# over_d <- 0.52
dim(incidence)
set.seed(1)
plot((incidence$I.6))
matplot(incidence[,-1])
# number of locations
N_geo <- ncol(incidence)-1
# Serial interval
mean_SI <- 14.2
CV_SI <- 9.6/14.2 # from http://www.nejm.org/doi/suppl/10.1056/NEJMc1414992/suppl_file/nejmc1414992_
SI <- SI_gamma_dist_EpiEstim(mu = mean_SI,
cv = CV_SI,
SItrunc = 40)
# final number of MCMC iterations (the whole thing,
# here with 10 locations runs in ~3.5mins) )
rep <- 2e3
sigma_prop <- rep(0.1,N_geo*2)         # initial proposal variances (they are now tuned!)
# initial incidence conditions
if ( N_geo>1 ){
mu0 <- colMeans(incidence[,-1])*mean_SI
}else{
mu0 <- mean(incidence[,-1])*mean_SI
}
# initially, we assume R=1 and choose initial condition accordingly, i.e. with mu0 case and R=1
# we expect the number of daily cases to stabilised at the mean of the observed incidence in the
# time window of interest
# this is use for the prior of initial number of cases, i.e. as the mean of an exponential distribution
# in practice, the mu0 cases will happen 100 days before the start of the time windows
theta0 <- c(rep(1,N_geo), mu0)          # initial parameter R=1 (time # of locations, and initial number of cases in the past)
# number of locations
N_geo <- ncol(incidence)-1
# Serial interval
mean_SI <- 14.2
CV_SI <- 9.6/14.2 # from http://www.nejm.org/doi/suppl/10.1056/NEJMc1414992/suppl_file/nejmc1414992_
SI <- SI_gamma_dist_EpiEstim(mu = mean_SI,
cv = CV_SI,
SItrunc = 40)
# final number of MCMC iterations (the whole thing,
# here with 10 locations runs in ~3.5mins) )
rep <- 1e4 #2e3
sigma_prop <- rep(0.1,N_geo*2)         # initial proposal variances (they are now tuned!)
# initial incidence conditions
if ( N_geo>1 ){
mu0 <- colMeans(incidence[,-1])*mean_SI
}else{
mu0 <- mean(incidence[,-1])*mean_SI
}
# initially, we assume R=1 and choose initial condition accordingly, i.e. with mu0 case and R=1
# we expect the number of daily cases to stabilised at the mean of the observed incidence in the
# time window of interest
# this is use for the prior of initial number of cases, i.e. as the mean of an exponential distribution
# in practice, the mu0 cases will happen 100 days before the start of the time windows
theta0 <- c(rep(1,N_geo), mu0)          # initial parameter R=1 (time # of locations, and initial number of cases in the past)
res <- MCMC_full(I = incidence,
N_geo = N_geo,
iter = rep,
theta0 = theta0,
s = sigma_prop,
SI = SI,
mu0 = mu0,
repli_adapt = 10,
within_iter = rep/10, over_disp = over_d)
Acc <- colSums(diff(res$theta)!=0)/rep          # acceptance rate (should be close to .2)
Acc
# plot traces
plot(res$logL[,1])                                  # of likelihood
layout(matrix(1:N_geo,2,ceiling(N_geo/2),byrow = TRUE))
for (i in 1:N_geo) plot(res$theta[,i])              # of R's
for (i in 1:N_geo) plot(res$theta[,N_geo+i])        # of initial conditions
if (N_geo>1){
R_est <- apply(res$theta[,1:N_geo],2,
quantile,c(.5,.025,.975))   # median and 95%CrI of Rs by locations
I0_est <- apply(res$theta[,(N_geo+1):(2*N_geo)],2,
quantile,c(.5,.025,.975))   # median and 95%CrI of I0
}else{
R_est <- quantile(res$theta[,1],c(.5,.025,.975))
I0_est <- quantile(res$theta[,2],c(.5,.025,.975))
}
save.image('test_on_simulation1.RData')             # saving so far
layout(matrix(1:2,1,2,byrow = TRUE))
errbar(1:N_geo,R_est[1,],R_est[2,],R_est[3,],
xlab = 'location', ylab = 'R',ylim = c(0,3), bty = 'n')
lines(c(1,N_geo),rep(R,2), col = 'red')
